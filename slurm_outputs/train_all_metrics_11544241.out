============================================================================================== 
Warning! Mixing Conda and module environments may lead to corruption of the
user environment. 
We do not recommend users mixing those two environments unless absolutely
necessary. Note that 
SURF does not provide any support for Conda environment.
For more information, please refer to our software policy page:
https://servicedesk.surf.nl/wiki/display/WIKI/Software+policy+Snellius#SoftwarepolicySnellius-UseofAnacondaandMinicondaenvironmentsonSnellius 

Remember that many packages have already been installed on the system and can
be loaded using 
the 'module load <package__name>' command. If you are uncertain if a package is
already available 
on the system, please use 'module avail' or 'module spider' to search for it.
============================================================================================== 
Checking whether the GPU is available
GPU available? True
Starting training for all metrics...

 Training model on metric: CLIP-IQA
Loaded 21616 train, 5404 val, 9239 test samples from ['MSFD', 'mice', 'pa_experiment_data', 'phantom', 'v_phantom', 'zenodo']
[Epoch 1/15] Train Loss: 0.0933 | Val Loss: 0.0646
✔ New best model saved to models/CLIP-IQA/best_model.pth with val_loss=0.0646
[Epoch 2/15] Train Loss: 0.0620 | Val Loss: 0.0678
[Epoch 3/15] Train Loss: 0.0579 | Val Loss: 0.0600
✔ New best model saved to models/CLIP-IQA/best_model.pth with val_loss=0.0600
[Epoch 4/15] Train Loss: 0.0565 | Val Loss: 0.0651
[Epoch 5/15] Train Loss: 0.0549 | Val Loss: 0.0574
✔ New best model saved to models/CLIP-IQA/best_model.pth with val_loss=0.0574
[Epoch 6/15] Train Loss: 0.0541 | Val Loss: 0.0567
✔ New best model saved to models/CLIP-IQA/best_model.pth with val_loss=0.0567
[Epoch 7/15] Train Loss: 0.0538 | Val Loss: 0.0513
✔ New best model saved to models/CLIP-IQA/best_model.pth with val_loss=0.0513
[Epoch 8/15] Train Loss: 0.0529 | Val Loss: 0.0509
✔ New best model saved to models/CLIP-IQA/best_model.pth with val_loss=0.0509
[Epoch 9/15] Train Loss: 0.0519 | Val Loss: 0.0434
✔ New best model saved to models/CLIP-IQA/best_model.pth with val_loss=0.0434
[Epoch 10/15] Train Loss: 0.0513 | Val Loss: 0.0435
[Epoch 11/15] Train Loss: 0.0510 | Val Loss: 0.0450
[Epoch 12/15] Train Loss: 0.0511 | Val Loss: 0.0431
✔ New best model saved to models/CLIP-IQA/best_model.pth with val_loss=0.0431
[Epoch 13/15] Train Loss: 0.0502 | Val Loss: 0.0428
✔ New best model saved to models/CLIP-IQA/best_model.pth with val_loss=0.0428
[Epoch 14/15] Train Loss: 0.0500 | Val Loss: 0.0453
[Epoch 15/15] Train Loss: 0.0498 | Val Loss: 0.0478
Saved training loss log to models/CLIP-IQA/train_val_loss.csv

 Training model on metric: SSIM
Loaded 21616 train, 5404 val, 9239 test samples from ['MSFD', 'mice', 'pa_experiment_data', 'phantom', 'v_phantom', 'zenodo']
[Epoch 1/15] Train Loss: 0.1412 | Val Loss: 0.0430
✔ New best model saved to models/SSIM/best_model.pth with val_loss=0.0430
[Epoch 2/15] Train Loss: 0.0673 | Val Loss: 0.0582
[Epoch 3/15] Train Loss: 0.0548 | Val Loss: 0.0581
[Epoch 4/15] Train Loss: 0.0525 | Val Loss: 0.0577
[Epoch 5/15] Train Loss: 0.0505 | Val Loss: 0.0543
[Epoch 6/15] Train Loss: 0.0498 | Val Loss: 0.0625
[Epoch 7/15] Train Loss: 0.0495 | Val Loss: 0.0603
[Epoch 8/15] Train Loss: 0.0499 | Val Loss: 0.0585
[Epoch 9/15] Train Loss: 0.0495 | Val Loss: 0.0530
[Epoch 10/15] Train Loss: 0.0489 | Val Loss: 0.0481
[Epoch 11/15] Train Loss: 0.0494 | Val Loss: 0.0557
[Epoch 12/15] Train Loss: 0.0491 | Val Loss: 0.0588
[Epoch 13/15] Train Loss: 0.0484 | Val Loss: 0.0565
[Epoch 14/15] Train Loss: 0.0480 | Val Loss: 0.0615
[Epoch 15/15] Train Loss: 0.0474 | Val Loss: 0.0540
Saved training loss log to models/SSIM/train_val_loss.csv

 Training model on metric: PSNR
Loaded 21616 train, 5404 val, 9239 test samples from ['MSFD', 'mice', 'pa_experiment_data', 'phantom', 'v_phantom', 'zenodo']
[Epoch 1/15] Train Loss: 8.4985 | Val Loss: 9.5258
✔ New best model saved to models/PSNR/best_model.pth with val_loss=9.5258
[Epoch 2/15] Train Loss: 7.1605 | Val Loss: 11.6943
[Epoch 3/15] Train Loss: 6.4405 | Val Loss: 9.7713
[Epoch 4/15] Train Loss: 5.2384 | Val Loss: 2.6276
✔ New best model saved to models/PSNR/best_model.pth with val_loss=2.6276
[Epoch 5/15] Train Loss: 4.1507 | Val Loss: 2.3790
✔ New best model saved to models/PSNR/best_model.pth with val_loss=2.3790
[Epoch 6/15] Train Loss: 4.0083 | Val Loss: 2.0225
✔ New best model saved to models/PSNR/best_model.pth with val_loss=2.0225
[Epoch 7/15] Train Loss: 3.9229 | Val Loss: 2.1606
[Epoch 8/15] Train Loss: 3.8385 | Val Loss: 1.7779
✔ New best model saved to models/PSNR/best_model.pth with val_loss=1.7779
[Epoch 9/15] Train Loss: 3.7216 | Val Loss: 1.9550
[Epoch 10/15] Train Loss: 3.6987 | Val Loss: 2.1036
[Epoch 11/15] Train Loss: 3.6303 | Val Loss: 1.7287
✔ New best model saved to models/PSNR/best_model.pth with val_loss=1.7287
[Epoch 12/15] Train Loss: 3.5530 | Val Loss: 1.7274
✔ New best model saved to models/PSNR/best_model.pth with val_loss=1.7274
[Epoch 13/15] Train Loss: 3.5575 | Val Loss: 2.0508
[Epoch 14/15] Train Loss: 3.4664 | Val Loss: 1.6705
✔ New best model saved to models/PSNR/best_model.pth with val_loss=1.6705
[Epoch 15/15] Train Loss: 3.4199 | Val Loss: 1.6125
✔ New best model saved to models/PSNR/best_model.pth with val_loss=1.6125
Saved training loss log to models/PSNR/train_val_loss.csv

 Training model on metric: VIF
Loaded 21616 train, 5404 val, 9239 test samples from ['MSFD', 'mice', 'pa_experiment_data', 'phantom', 'v_phantom', 'zenodo']
[Epoch 1/15] Train Loss: 0.1018 | Val Loss: 0.0696
✔ New best model saved to models/VIF/best_model.pth with val_loss=0.0696
[Epoch 2/15] Train Loss: 0.0689 | Val Loss: 0.0553
✔ New best model saved to models/VIF/best_model.pth with val_loss=0.0553
[Epoch 3/15] Train Loss: 0.0656 | Val Loss: 0.0418
✔ New best model saved to models/VIF/best_model.pth with val_loss=0.0418
[Epoch 4/15] Train Loss: 0.0639 | Val Loss: 0.0512
[Epoch 5/15] Train Loss: 0.0629 | Val Loss: 0.0496
[Epoch 6/15] Train Loss: 0.0623 | Val Loss: 0.0473
[Epoch 7/15] Train Loss: 0.0619 | Val Loss: 0.0534
[Epoch 8/15] Train Loss: 0.0610 | Val Loss: 0.0512
[Epoch 9/15] Train Loss: 0.0609 | Val Loss: 0.0546
[Epoch 10/15] Train Loss: 0.0609 | Val Loss: 0.0496
[Epoch 11/15] Train Loss: 0.0607 | Val Loss: 0.0582
[Epoch 12/15] Train Loss: 0.0600 | Val Loss: 0.0610
[Epoch 13/15] Train Loss: 0.0599 | Val Loss: 0.0593
[Epoch 14/15] Train Loss: 0.0594 | Val Loss: 0.0599
[Epoch 15/15] Train Loss: 0.0597 | Val Loss: 0.0572
Saved training loss log to models/VIF/train_val_loss.csv

 Training model on metric: GMSD
Loaded 21616 train, 5404 val, 9239 test samples from ['MSFD', 'mice', 'pa_experiment_data', 'phantom', 'v_phantom', 'zenodo']
[Epoch 1/15] Train Loss: 0.0321 | Val Loss: 0.0286
✔ New best model saved to models/GMSD/best_model.pth with val_loss=0.0286
[Epoch 2/15] Train Loss: 0.0287 | Val Loss: 0.0283
✔ New best model saved to models/GMSD/best_model.pth with val_loss=0.0283
[Epoch 3/15] Train Loss: 0.0287 | Val Loss: 0.0283
[Epoch 4/15] Train Loss: 0.0286 | Val Loss: 0.0285
[Epoch 5/15] Train Loss: 0.0286 | Val Loss: 0.0283
✔ New best model saved to models/GMSD/best_model.pth with val_loss=0.0283
[Epoch 6/15] Train Loss: 0.0286 | Val Loss: 0.0284
[Epoch 7/15] Train Loss: 0.0287 | Val Loss: 0.0283
[Epoch 8/15] Train Loss: 0.0286 | Val Loss: 0.0288
[Epoch 9/15] Train Loss: 0.0286 | Val Loss: 0.0283
✔ New best model saved to models/GMSD/best_model.pth with val_loss=0.0283
[Epoch 10/15] Train Loss: 0.0286 | Val Loss: 0.0283
✔ New best model saved to models/GMSD/best_model.pth with val_loss=0.0283
[Epoch 11/15] Train Loss: 0.0286 | Val Loss: 0.0283
[Epoch 12/15] Train Loss: 0.0286 | Val Loss: 0.0284
[Epoch 13/15] Train Loss: 0.0286 | Val Loss: 0.0283
[Epoch 14/15] Train Loss: 0.0286 | Val Loss: 0.0283
[Epoch 15/15] Train Loss: 0.0286 | Val Loss: 0.0283
Saved training loss log to models/GMSD/train_val_loss.csv

 Training model on metric: HAARPSI
Loaded 21616 train, 5404 val, 9239 test samples from ['MSFD', 'mice', 'pa_experiment_data', 'phantom', 'v_phantom', 'zenodo']
[Epoch 1/15] Train Loss: 0.0899 | Val Loss: 0.0718
✔ New best model saved to models/HAARPSI/best_model.pth with val_loss=0.0718
[Epoch 2/15] Train Loss: 0.0773 | Val Loss: 0.0725
[Epoch 3/15] Train Loss: 0.0757 | Val Loss: 0.0724
[Epoch 4/15] Train Loss: 0.0738 | Val Loss: 0.0660
✔ New best model saved to models/HAARPSI/best_model.pth with val_loss=0.0660
[Epoch 5/15] Train Loss: 0.0709 | Val Loss: 0.0616
✔ New best model saved to models/HAARPSI/best_model.pth with val_loss=0.0616
[Epoch 6/15] Train Loss: 0.0670 | Val Loss: 0.0627
[Epoch 7/15] Train Loss: 0.0642 | Val Loss: 0.0554
✔ New best model saved to models/HAARPSI/best_model.pth with val_loss=0.0554
[Epoch 8/15] Train Loss: 0.0617 | Val Loss: 0.0538
✔ New best model saved to models/HAARPSI/best_model.pth with val_loss=0.0538
[Epoch 9/15] Train Loss: 0.0596 | Val Loss: 0.0519
✔ New best model saved to models/HAARPSI/best_model.pth with val_loss=0.0519
[Epoch 10/15] Train Loss: 0.0574 | Val Loss: 0.0577
[Epoch 11/15] Train Loss: 0.0565 | Val Loss: 0.0494
✔ New best model saved to models/HAARPSI/best_model.pth with val_loss=0.0494
[Epoch 12/15] Train Loss: 0.0548 | Val Loss: 0.0507
[Epoch 13/15] Train Loss: 0.0545 | Val Loss: 0.0536
[Epoch 14/15] Train Loss: 0.0539 | Val Loss: 0.0471
✔ New best model saved to models/HAARPSI/best_model.pth with val_loss=0.0471
[Epoch 15/15] Train Loss: 0.0528 | Val Loss: 0.0565
Saved training loss log to models/HAARPSI/train_val_loss.csv

 Training model on metric: MSSSIM
Loaded 21616 train, 5404 val, 9239 test samples from ['MSFD', 'mice', 'pa_experiment_data', 'phantom', 'v_phantom', 'zenodo']
[Epoch 1/15] Train Loss: 0.1380 | Val Loss: 0.0579
✔ New best model saved to models/MSSSIM/best_model.pth with val_loss=0.0579
[Epoch 2/15] Train Loss: 0.0667 | Val Loss: 0.0545
✔ New best model saved to models/MSSSIM/best_model.pth with val_loss=0.0545
[Epoch 3/15] Train Loss: 0.0564 | Val Loss: 0.0553
[Epoch 4/15] Train Loss: 0.0554 | Val Loss: 0.0547
[Epoch 5/15] Train Loss: 0.0552 | Val Loss: 0.0547
[Epoch 6/15] Train Loss: 0.0551 | Val Loss: 0.0547
[Epoch 7/15] Train Loss: 0.0551 | Val Loss: 0.0547
[Epoch 8/15] Train Loss: 0.0551 | Val Loss: 0.0548
[Epoch 9/15] Train Loss: 0.0551 | Val Loss: 0.0547
[Epoch 10/15] Train Loss: 0.0551 | Val Loss: 0.0547
[Epoch 11/15] Train Loss: 0.0551 | Val Loss: 0.0548
[Epoch 12/15] Train Loss: 0.0551 | Val Loss: 0.0547
[Epoch 13/15] Train Loss: 0.0550 | Val Loss: 0.0547
[Epoch 14/15] Train Loss: 0.0551 | Val Loss: 0.0548
[Epoch 15/15] Train Loss: 0.0551 | Val Loss: 0.0547
Saved training loss log to models/MSSSIM/train_val_loss.csv

 Training model on metric: IWSSIM
Loaded 21616 train, 5404 val, 9239 test samples from ['MSFD', 'mice', 'pa_experiment_data', 'phantom', 'v_phantom', 'zenodo']
[Epoch 1/15] Train Loss: 0.1316 | Val Loss: 0.0882
✔ New best model saved to models/IWSSIM/best_model.pth with val_loss=0.0882
[Epoch 2/15] Train Loss: 0.0773 | Val Loss: 0.0500
✔ New best model saved to models/IWSSIM/best_model.pth with val_loss=0.0500
[Epoch 3/15] Train Loss: 0.0623 | Val Loss: 0.0556
[Epoch 4/15] Train Loss: 0.0578 | Val Loss: 0.0439
✔ New best model saved to models/IWSSIM/best_model.pth with val_loss=0.0439
[Epoch 5/15] Train Loss: 0.0559 | Val Loss: 0.0454
[Epoch 6/15] Train Loss: 0.0550 | Val Loss: 0.0473
[Epoch 7/15] Train Loss: 0.0541 | Val Loss: 0.0433
✔ New best model saved to models/IWSSIM/best_model.pth with val_loss=0.0433
[Epoch 8/15] Train Loss: 0.0531 | Val Loss: 0.0489
[Epoch 9/15] Train Loss: 0.0532 | Val Loss: 0.0436
[Epoch 10/15] Train Loss: 0.0527 | Val Loss: 0.0497
[Epoch 11/15] Train Loss: 0.0524 | Val Loss: 0.0447
[Epoch 12/15] Train Loss: 0.0519 | Val Loss: 0.0437
[Epoch 13/15] Train Loss: 0.0515 | Val Loss: 0.0486
[Epoch 14/15] Train Loss: 0.0507 | Val Loss: 0.0451
[Epoch 15/15] Train Loss: 0.0508 | Val Loss: 0.0470
Saved training loss log to models/IWSSIM/train_val_loss.csv

 Training model on metric: MSGMSD
Loaded 21616 train, 5404 val, 9239 test samples from ['MSFD', 'mice', 'pa_experiment_data', 'phantom', 'v_phantom', 'zenodo']
[Epoch 1/15] Train Loss: 0.0310 | Val Loss: 0.0297
✔ New best model saved to models/MSGMSD/best_model.pth with val_loss=0.0297
[Epoch 2/15] Train Loss: 0.0301 | Val Loss: 0.0300
[Epoch 3/15] Train Loss: 0.0300 | Val Loss: 0.0297
[Epoch 4/15] Train Loss: 0.0300 | Val Loss: 0.0297
[Epoch 5/15] Train Loss: 0.0300 | Val Loss: 0.0298
[Epoch 6/15] Train Loss: 0.0300 | Val Loss: 0.0297
[Epoch 7/15] Train Loss: 0.0300 | Val Loss: 0.0299
[Epoch 8/15] Train Loss: 0.0300 | Val Loss: 0.0297
✔ New best model saved to models/MSGMSD/best_model.pth with val_loss=0.0297
[Epoch 9/15] Train Loss: 0.0300 | Val Loss: 0.0298
[Epoch 10/15] Train Loss: 0.0300 | Val Loss: 0.0298
[Epoch 11/15] Train Loss: 0.0300 | Val Loss: 0.0299
[Epoch 12/15] Train Loss: 0.0300 | Val Loss: 0.0297
[Epoch 13/15] Train Loss: 0.0300 | Val Loss: 0.0298
[Epoch 14/15] Train Loss: 0.0300 | Val Loss: 0.0297
✔ New best model saved to models/MSGMSD/best_model.pth with val_loss=0.0297
[Epoch 15/15] Train Loss: 0.0300 | Val Loss: 0.0298
Saved training loss log to models/MSGMSD/train_val_loss.csv

 Training model on metric: BRISQUE
Loaded 21616 train, 5404 val, 9239 test samples from ['MSFD', 'mice', 'pa_experiment_data', 'phantom', 'v_phantom', 'zenodo']
[Epoch 1/15] Train Loss: 25.1266 | Val Loss: 40.8544
✔ New best model saved to models/BRISQUE/best_model.pth with val_loss=40.8544
[Epoch 2/15] Train Loss: 19.7974 | Val Loss: 47.4023
[Epoch 3/15] Train Loss: 18.7131 | Val Loss: 49.1366
[Epoch 4/15] Train Loss: 17.8443 | Val Loss: 45.0051
[Epoch 5/15] Train Loss: 16.9737 | Val Loss: 43.4858
[Epoch 6/15] Train Loss: 16.2620 | Val Loss: 36.2934
✔ New best model saved to models/BRISQUE/best_model.pth with val_loss=36.2934
[Epoch 7/15] Train Loss: 15.0784 | Val Loss: 33.7713
✔ New best model saved to models/BRISQUE/best_model.pth with val_loss=33.7713
[Epoch 8/15] Train Loss: 14.0728 | Val Loss: 23.9960
✔ New best model saved to models/BRISQUE/best_model.pth with val_loss=23.9960
[Epoch 9/15] Train Loss: 12.6947 | Val Loss: 9.8406
✔ New best model saved to models/BRISQUE/best_model.pth with val_loss=9.8406
[Epoch 10/15] Train Loss: 11.8388 | Val Loss: 4.3854
✔ New best model saved to models/BRISQUE/best_model.pth with val_loss=4.3854
[Epoch 11/15] Train Loss: 11.1009 | Val Loss: 3.6226
✔ New best model saved to models/BRISQUE/best_model.pth with val_loss=3.6226
[Epoch 12/15] Train Loss: 10.9149 | Val Loss: 4.3840
[Epoch 13/15] Train Loss: 10.8219 | Val Loss: 3.9251
[Epoch 14/15] Train Loss: 10.6855 | Val Loss: 3.7004
[Epoch 15/15] Train Loss: 10.3878 | Val Loss: 4.3280
Saved training loss log to models/BRISQUE/train_val_loss.csv

 Training model on metric: TV
Loaded 21616 train, 5404 val, 9239 test samples from ['MSFD', 'mice', 'pa_experiment_data', 'phantom', 'v_phantom', 'zenodo']
[Epoch 1/15] Train Loss: 1.2002 | Val Loss: 0.7668
✔ New best model saved to models/TV/best_model.pth with val_loss=0.7668
[Epoch 2/15] Train Loss: 0.8408 | Val Loss: 0.3848
✔ New best model saved to models/TV/best_model.pth with val_loss=0.3848
[Epoch 3/15] Train Loss: 0.7633 | Val Loss: 0.4718
[Epoch 4/15] Train Loss: 0.7176 | Val Loss: 0.3835
✔ New best model saved to models/TV/best_model.pth with val_loss=0.3835
[Epoch 5/15] Train Loss: 0.6931 | Val Loss: 0.3930
[Epoch 6/15] Train Loss: 0.6626 | Val Loss: 0.3661
✔ New best model saved to models/TV/best_model.pth with val_loss=0.3661
[Epoch 7/15] Train Loss: 0.6302 | Val Loss: 0.4243
[Epoch 8/15] Train Loss: 0.6089 | Val Loss: 0.4806
[Epoch 9/15] Train Loss: 0.6106 | Val Loss: 0.4377
[Epoch 10/15] Train Loss: 0.5913 | Val Loss: 0.4311
[Epoch 11/15] Train Loss: 0.5803 | Val Loss: 0.5251
[Epoch 12/15] Train Loss: 0.5758 | Val Loss: 0.4820
[Epoch 13/15] Train Loss: 0.5723 | Val Loss: 0.5916
[Epoch 14/15] Train Loss: 0.5614 | Val Loss: 0.5901
[Epoch 15/15] Train Loss: 0.5569 | Val Loss: 0.4943
Saved training loss log to models/TV/train_val_loss.csv

JOB STATISTICS
==============
Job ID: 11544241
Cluster: snellius
User/Group: mvanderbrugge/mvanderbrugge
State: RUNNING
Nodes: 1
Cores per node: 18
CPU Utilized: 00:00:04
CPU Efficiency: 0.00% of 1-22:02:06 core-walltime
Job Wall-clock time: 02:33:27
Memory Utilized: 1.65 MB
Memory Efficiency: 0.00% of 120.00 GB (120.00 GB/node)
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
